{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint 4 - Sprint Machine Learning Scratch Logistic Regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOIXGYdZUtQ2SBAsG7fIAh9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7-4tZxH5P3LF"},"source":["#The purpose of this Sprint"]},{"cell_type":"markdown","metadata":{"id":"d3xmwLegQCbg"},"source":["* Understanding logistic regression through scratch\n","* Learn the basics about classification problems"]},{"cell_type":"markdown","metadata":{"id":"X3Btg2c1QGc2"},"source":["#**[Problem 1] Hypothetical function**"]},{"cell_type":"code","metadata":{"id":"zDTqoCcY-OZr","executionInfo":{"status":"ok","timestamp":1616453318240,"user_tz":0,"elapsed":2032,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","\n","from sklearn.datasets import load_iris\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import precision_score\n","from sklearn.metrics import recall_score\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import confusion_matrix\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from tempfile import TemporaryFile"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"N1kCINYk-PJf","executionInfo":{"status":"ok","timestamp":1616624303521,"user_tz":0,"elapsed":924,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}}},"source":["class ScratchLogisticRegression ():\n","    \"\"\"\n","    Logistic regression scratch implementation\n","\n","    Parameters\n","    ----------\n","    num_iter: int\n","      Number of iterations\n","    lr: float\n","      Learning rate\n","    no_bias: bool\n","      True if no bias term is included\n","    verbose: bool\n","      True to output the learning process\n","\n","    Attributes\n","    ----------\n","    self.coef_: ndarray, shape (n_features,) of the following form\n","      Parameters\n","    self.loss: ndarray of the following form, shape (self.iter,)\n","      Record losses on training data\n","    self.val_loss: ndarray, shape (self.iter,) of the following form\n","      Record losses on validation data\n","    \"\"\"\n","\n","    def __init__ (self, num_iter, lr, no_bias, verbose, regularization = 0.5):\n","        # Record hyperparameters as attributes\n","        self.iter = num_iter\n","        self.lr = lr\n","        self.no_bias = no_bias\n","        self.verbose = verbose\n","        # Prepare an array to record the loss\n","        self.loss = np.zeros (self.iter)\n","        self.val_loss = np.zeros (self.iter)\n","        \n","        self.regularization = regularization\n","\n","    def fit (self, X, y, X_val = None, y_val = None):\n","        \"\"\"\n","        Learn logistic regression. If verification data is entered, the loss and accuracy for it are also calculated for each iteration.\n","\n","        Parameters\n","        ----------\n","        X: ndarray, shape (n_samples, n_features) of the following form\n","            Features of training data\n","        y: ndarray, shape (n_samples,) of the following form\n","            Correct value of training data\n","        X_val: ndarray, shape (n_samples, n_features) of the following form\n","            Features of verification data\n","        y_val: ndarray, shape (n_samples,) of the following form\n","            Correct value of verification data\n","        \"\"\"\n","\n","        self.val_enable = False\n","        if X_val is not None:\n","            self.val_enable = True\n","        \n","        if not self.no_bias:\n","            X = np.concatenate ([np.ones (X.shape [0]). Reshape (-1,1), X], axis = 1)\n","            if self.val_enable:\n","                X_val = np.concatenate ([np.ones (X_val.shape [0]). Reshape (-1,1), X_val], axis = 1)\n","        \n","        n_features = X.shape [1]\n","        #Parameter (weight)\n","        self.coef_ = np.random.rand (n_features)\n","        \n","        for i in range (self.iter):\n","            self._gradient_descent (X, self._logistic_hypothesis (X) --y)\n","            self.loss [i] = self._cost (y, self._logistic_hypothesis (X))\n","            if self.val_enable:\n","                self.val_loss [i] = self._cost (y_val, self._logistic_hypothesis (X_val))\n","        \n","        if self.verbose:\n","            self.learning_curve ()\n","            print ()\n","        pass\n","\n","\n","    def predict (self, X):\n","        \"\"\"\n","        Estimate the label using logistic regression.\n","\n","        Parameters\n","        ----------\n","        X: ndarray, shape (n_samples, n_features) of the following form\n","            sample\n","\n","        Returns\n","        -------\n","            The following form of ndarray, shape (n_samples, 1)\n","            Estimated result by logistic regression\n","        \"\"\"\n","        \n","        threshold = 0.5\n","        return (self.predict_proba (X)> threshold) .astype (int)\n","        \n","    def predict_proba (self, X):\n","        \"\"\"\n","        Estimate the probability using logistic regression.\n","\n","        Parameters\n","        ----------\n","        X: ndarray, shape (n_samples, n_features) of the following form\n","            sample\n","\n","        Returns\n","        -------\n","            The following form of ndarray, shape (n_samples, 1)\n","            Estimated result by logistic regression\n","        \"\"\"\n","        if not self.no_bias:\n","            X = np.concatenate ([np.ones (X.shape [0]). Reshape (-1,1), X], axis = 1)\n","        \n","        return self._logistic_hypothesis (X)\n","\n","    def _logistic_hypothesis (self, X):\n","        \"\"\"\n","        Compute the hypothetical function of logistic regression\n","\n","        Parameters\n","        ----------\n","        X: ndarray, shape (n_samples, n_features) of the following form\n","          Training data\n","\n","        Returns\n","        -------\n","          The following form of ndarray, shape (n_samples, 1)\n","          Estimated result by linear hypothetical function\n","        \n","        \"\"\"\n","        h = X@self.coef_\n","        g = 1 / (1 + np.exp (-h))\n","        return g\n","    \n","    def _gradient_descent (self, X, error):\n","        \"\"\"\n","        Learn by the steepest descent method (once)\n","        \n","        Parameters\n","        ----------\n","        X: ndarray, shape (n_samples, n_features) of the following form\n","          Training data\n","\n","        Returns\n","        -------\n","        There is no return\n","        \n","        \"\"\"\n","        \n","        self.coef_ = self.coef_ - self.lr*(np.average(error*X.T, axis=1) + (self.regularization/X.shape[0])*np.concatenate([np.array([0]), self.coef_[1:]]))\n","        return\n","    \n","    def _cost(self, y_true, y_pred_proba):\n","        j = np.average(-y_true*np.log(y_pred_proba) -(1-y_true)*np.log(1-y_pred_proba)) + (self.regularization/(2*len(y_true)))*np.sum(self.coef_[1:])\n","        return j\n","    \n","    def learning_curve(self):\n","        plt.title(\"model loss\")\n","        plt.xlabel(\"iter\")\n","        plt.ylabel(\"loss\")\n","        plt.plot(np.arange(self.iter), self.loss, label=\"loss\")\n","        if self.val_enable:\n","            plt.plot(np.arange(self.iter), self.val_loss, label=\"val_loss\")\n","        plt.legend()\n","        plt.show()"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TcUPL_aIEJcR"},"source":["#**[Problem 2] Steepest descent**"]},{"cell_type":"markdown","metadata":{"id":"J3Hv9YjNCVxR"},"source":["**[Answer]** Implemented in the above ScratchLogisticRegression class"]},{"cell_type":"markdown","metadata":{"id":"56ubaZoaFAFI"},"source":["#**[Problem 3] Estimated**"]},{"cell_type":"markdown","metadata":{"id":"BaXsypbPFYSP"},"source":["**[Answer]** Implemented in the above ScratchLogisticRegression class"]},{"cell_type":"markdown","metadata":{"id":"tbDOph3VFt4k"},"source":["#**[Problem 4] Objective function**"]},{"cell_type":"markdown","metadata":{"id":"rVneg22zF3fz"},"source":["**[Answer]** Implemented in the above ScratchLogisticRegression class\n"]},{"cell_type":"markdown","metadata":{"id":"NtLxiFZ7F7Xy"},"source":["#**[Problem 5] Learning and estimation**"]},{"cell_type":"code","metadata":{"id":"koqC5QBnGYqz","executionInfo":{"status":"ok","timestamp":1616624444116,"user_tz":0,"elapsed":1892,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}}},"source":["def scratch_train_test_split (X, y, train_size = 0.8,):\n","    \"\"\"\n","    Divide the verification data.\n","\n","    Parameters\n","    ----------\n","    X: ndarray, shape (n_samples, n_features) of the following form\n","      Learning data\n","    y: ndarray, shape (n_samples,) of the following form\n","      Correct answer value\n","    train_size: float (0 <train_size <1)\n","      Specify what percentage to use as a train\n","\n","    Returns\n","    ----------\n","    X_train: ndarray, shape (n_samples, n_features) of the following form\n","      Learning data\n","    X_test: ndarray, shape (n_samples, n_features) of the following form\n","      Validation data\n","    y_train: ndarray, shape (n_samples,) of the following form\n","      Correct answer value of training data\n","    y_test: ndarray, shape (n_samples,) of the following form\n","      Correct value of verification data\n","    \"\"\"\n","    n_samples = len (X)\n","    idx = np.zeros (n_samples)\n","    train_size = int (n_samples * train_size)\n","    train_idx = np.random.choice (np.arange (n_samples), train_size, replace = False)\n","    idx [train_idx] = 1\n","    \n","    X_train, X_test = X [idx == 1], X [idx == 0]\n","    y_train, y_test = y [idx == 1], y [idx == 0]\n","    \n","    return X_train, X_test, y_train, y_test"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWWMSEVwGibF","executionInfo":{"status":"ok","timestamp":1616624458960,"user_tz":0,"elapsed":5578,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}}},"source":["def evalate(y_true, y_pred):\n","    print(\"accuracy =\", accuracy_score(y_true, y_pred))\n","    print(\"precision =\", precision_score(y_true, y_pred, average='macro'))\n","    print(\"recall =\", recall_score(y_true, y_pred, average='macro'))\n","    print(\"f1 =\", f1_score(y_true, y_pred, average='macro'))\n","    print(confusion_matrix(y_true, y_pred))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"X92kHY-MGlKk","executionInfo":{"status":"error","timestamp":1616624501541,"user_tz":0,"elapsed":1195,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}},"outputId":"77943c0b-3f8e-4a5b-d604-35093255d7c4"},"source":["iris_data = load_iris()\n","x1, x2 = 2,3\n","iris_X = iris_data.data[iris_data.target!=0][:,[x1,x2]]\n","iris_y = iris_data.target[iris_data.target!=0] - 1\n","iris_target_names = iris_data.target_names[1:]\n","iris_feature_names = iris_data.feature_names[x1],iris_data.feature_names[x2]\n","iris_X[:5], iris_y[:5], iris_target_names, iris_feature_names"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-d09942e4abff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miris_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miris_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miris_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miris_target_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miris_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'load_iris' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jT4TKXL-GpF3","executionInfo":{"status":"error","timestamp":1616624517823,"user_tz":0,"elapsed":9782,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}},"outputId":"85d8d4be-b931-4615-9bfa-216a948ef33b"},"source":["scratch_logistic = ScratchLogisticRegression(num_iter=10000, lr=0.05, no_bias=False, verbose=True, regularization=0.1)\n","iris_X_train, iris_X_test, iris_y_train, iris_y_test = scratch_train_test_split(iris_X, iris_y)\n","scratch_logistic.fit(iris_X_train, iris_y_train, iris_X_test, iris_y_test)\n","y_pred = scratch_logistic.predict(iris_X_test)\n","evalate(iris_y_test, y_pred)"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-259c6bc1de74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscratch_logistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratchLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miris_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscratch_train_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscratch_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscratch_logistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevalate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-177ea980183f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_iter, lr, no_bias, verbose, regularization)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Prepare an array to record the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"id":"U3dzodFOGtOX","executionInfo":{"status":"error","timestamp":1616453556206,"user_tz":0,"elapsed":658,"user":{"displayName":"Alhaji Fortune","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRAlZlGyDc_Zt44Np56ATuWZ8e4dV8jJpSTrPmcDQ=s64","userId":"01218923895066088452"}},"outputId":"7d7f32b0-7568-491c-8711-9d72ba369cbf"},"source":["logistic = LogisticRegression()\n","logistic.fit(iris_X_train, iris_y_train)\n","y_pred = logistic.predict(iris_X_test)\n","evalate(iris_y_test, y_pred)"],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-139c731633f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevalate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_y_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'iris_X_train' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"FZJDoCV9G7yP"},"source":["#**[Problem 6] Plot of learning curve**"]},{"cell_type":"markdown","metadata":{"id":"ZlCiYXMPHG6w"},"source":["Added the learning_curve method to the ScratchLogisticRegression class and added it to the fit method of the ScratchLogisticRegression class. Execution was done in question 6. Looking at the graph, it was confirmed that the loss was reduced appropriately."]},{"cell_type":"markdown","metadata":{"id":"ICF__bmIHNmv"},"source":["#**[Problem 7] Visualization of decision area**"]},{"cell_type":"code","metadata":{"id":"mkhVPJA7Hc54"},"source":["def decision_region (X, y, model, step = 0.01, title ='decision region', xlabel ='xlabel', ylabel ='ylabel', target_names = ['versicolor','virginica']):\n","    \"\" \"\n","    Draw the determination area of ​​the model that learned binary classification with two-dimensional features.\n","    The background color is drawn from the estimated values ​​from the trained model.\n","    The points on the scatter plot are training or validation data.\n","\n","    Parameters\n","    ---------------- ----------------\n","    X: ndarray, shape (n_samples, 2)\n","        Feature value\n","    y: ndarray, shape (n_samples,)\n","        label\n","    model: object\n","        Insert the installed model of the learned model\n","    step: float, (default: 0.1)\n","        Set the interval to calculate the estimate\n","    title: str\n","        Give the text of the graph title\n","    xlabel, ylabel: str\n","        Give the text of the axis label\n","    target_names =: list of str\n","        Give a list of legends\n","    \"\" \"\n","    # setting\n","    scatter_color = ['red','blue']\n","    contourf_color = ['pink','skyblue']\n","    n_class = 2\n","\n","    # pred\n","    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n","    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n","    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n","\n","    # plot\n","    plt.title(title)\n","    plt.xlabel(xlabel)\n","    plt.ylabel(ylabel)\n","    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n","    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n","    for i, target in enumerate(set(y)):\n","        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n","    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n","    plt.legend(handles=patches)\n","    plt.legend()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bns9v1W4HlKL"},"source":["xlabel, ylabel = iris_feature_names\n","\n","decision_region(iris_X_train, iris_y_train, scratch_logistic, title='scratch_logistic_train', xlabel=xlabel, ylabel=ylabel)\n","decision_region(iris_X_test, iris_y_test, scratch_logistic, title='scratch_logistic_test', xlabel=xlabel, ylabel=ylabel)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g23zy4iXHo8s"},"source":["decision_region(iris_X_train, iris_y_train, logistic, title='logistic_train', xlabel=xlabel, ylabel=ylabel)\n","decision_region(iris_X_test, iris_y_test, logistic, title='logistic_test', xlabel=xlabel, ylabel=ylabel)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SlmlWFpcH05n"},"source":["#**[Problem 8] (Advance assignment) Saving weights**"]},{"cell_type":"markdown","metadata":{"id":"HZQDLwyXH7_j"},"source":["* Let's save and load the learned weights for easy verification. Use the pickle module and NumPy's np.savez."]}]}